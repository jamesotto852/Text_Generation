---
title: "Text Generation (Appendix)"
author: "James Otto"
date: "10/22/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This is the appendix to the series on text generation with recursive neural networks.
Here, we detail how we gathered, cleaned, and transformed the data necessary to train the models we considered.

First, we load in the necessary packages:
```{r setup_visible, message=FALSE, warning=FALSE}
library("tidyverse")
library("here")
```

***

## Downloading Books

First, we create a function which will automates the process of downloading `.txt` files from [Project Gutenberg](https://www.gutenberg.org/).
```{r source_download_gutenberg, echo = FALSE}
source(here("R/download_gutenberg.R"), local = knitr::knit_global())
```
```{r show_download_gutenberg, code=xfun::read_utf8(here::here("R/download_gutenberg.R"))}
```

Now, we download a few files:
```{r downloading_files, eval = FALSE}
# Frankenstein
download_gutenberg("https://www.gutenberg.org/files/84/84-0.txt", "Merry Shelley", "Frankenstein")

# Lewis Carrol's Alice in Wonderland Series
download_gutenberg("https://www.gutenberg.org/files/11/11-0.txt", "Lewis Carrol", "Alice_in_Wonderland")
download_gutenberg("https://www.gutenberg.org/files/12/12-0.txt", "Lewis Carrol", "Through_the_Looking_Glass")

# The works of Jane Austen
download_gutenberg("https://www.gutenberg.org/files/158/158-0.txt", "Jane Austen", "Emma")
download_gutenberg("https://www.gutenberg.org/files/1342/1342-0.txt", "Jane Austen", "Pride_and_Prejudice")
download_gutenberg("https://www.gutenberg.org/files/141/141-0.txt", "Jane Austen", "Mansfield_Park")
download_gutenberg("https://www.gutenberg.org/cache/epub/105/pg105.txt", "Jane Austen", "Persuasion")
download_gutenberg("https://www.gutenberg.org/files/121/121-0.txt", "Jane Austen", "Northanger_Abbey")
download_gutenberg("https://www.gutenberg.org/files/161/161-0.txt", "Jane Austen", "Sense_and_Sensibility")
```

Below, we include the first few lines of the downloaded Frankenstein file:
```{r printing_raw_lines, options}
read_lines(here("Data/Gutenberg/raw/Merry Shelley/Frankenstein.txt"))[1:85]
```

***

## Cleaning Books

Now, we need to clean the files.
As illustrated above, Project Gutenberg has a standardized system for marking the beginning and end of the original text.
These are indicated by the 1st and 2nd lines containing the string `"***"`.
There is still some metadata included in the cleaned files, for example the table of contents and chapter headings. 
Considering the relatively small volume this takes up, we are okay with leaving it (Project Gutenberg does not standardize these across their files).

Also, the data is currently stored as a character vector with elements corresponding to arbitrary groups of words.
The models we will be considering process data on a character level -- we need to break up the elements into individual characters.

```{r source_clean_gutenberg, echo = FALSE}
source(here("R/clean_gutenberg.R"), local = knitr::knit_global())
```
```{r show_clean_gutenberg, code=xfun::read_utf8(here::here("R/clean_gutenberg.R"))}
```

```{r cleaning_books, eval = FALSE}
authors <- list.files(here("Data/Gutenberg/raw")) 
works <- map(authors, \(x) list.files(here("Data/Gutenberg/raw", x)))

walk2(authors, works, clean_gutenberg)
```

Below, we include the first few lines of the cleaned Frankenstein file:
```{r printing_clean_lines, options}
read_lines(file = here("Data/Gutenberg/cleaned/Merry Shelley/Frankenstein.txt"))[1:79]
```

***



## Creating Training Data

Now, we are ready to create the training data for our tensorflow models.
We need to do quite a bit of work in order to get the data in the correct form.
As we will eventually be training 30 models for each author (for sequences of lengths 1 to 30),
we need to create 30 different training data sets per author.

Additionally, we the tensorflow models need numerical inputs -- not characters.
Importantly, the ordering and scale of the numerical inputs is irrelevant.
All that matters is that the function mapping characters to integers is invertible.
For each author, we create an encoder/decoder pair arbitrarily based on the empirical frequency distribution of characters.

Below, we include the helper functions which perform these tasks --
the end goal is to create a directory for each author containing the 30 different data sets;
the original corpus; and the encoder and decoder functions.
```{r source_create_training_data, echo = FALSE}
source(here("R/create_training_data.R"), local = knitr::knit_global())
```
```{r show_create_training_data, code=xfun::read_utf8(here::here("R/create_training_data.R"))}
```

```{r creating_training_data, eval = FALSE}
walk(authors, write_train_data, 30)
```

***
Below, we include the first few training observations corresponding to Merry Shelley 
corresponding to the data sets of sequences of lengths 1, 2, and 6.
The first set of observations are encoded in the machine-readable format tensorflow needs.
The following set are decoded, presented in a human-readable format.
Notice, in each case the $Y$ column is the target --
given the previous characters ($X_i$) it is our goal to accurately predict the next character ($Y$).

At this point, the data is in the format necessary to train our models,
see (blog posts 1 and 2) for details on implementation and results!

```{r printing_training_data_1, message = FALSE}
Shelley_data <- read_rds(here("Data/Training_Data/Merry Shelley/data.RDS"))
Shelley_df_seq_1 <- read_csv(here("Data/Training_Data/Merry Shelley/df_seq_1.csv"))
Shelley_df_seq_2 <- read_csv(here("Data/Training_Data/Merry Shelley/df_seq_2.csv"))
Shelley_df_seq_6 <- read_csv(here("Data/Training_Data/Merry Shelley/df_seq_6.csv"))
```

```{r printing_training_data_2, collapse = TRUE}
# Printing the first few encoded rows

head(Shelley_df_seq_1)

head(Shelley_df_seq_2)

head(Shelley_df_seq_6)
```

```{r printing_training_data_3, collapse = TRUE}
# Printing the above rows, decoded

head(Shelley_df_seq_1) |> mutate(across(everything(), Shelley_data$decoder))

head(Shelley_df_seq_2) |> mutate(across(everything(), Shelley_data$decoder))

head(Shelley_df_seq_6) |> mutate(across(everything(), Shelley_data$decoder))
```


